{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ[\"PINECONE_KEY\"]\n",
    "PINECONE_INDEX_NAME = \"documentations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings,\n",
    "      # optional if you're not using namespaces\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- STATE DEFINITION -----------\n",
    "class GraphState(TypedDict):\n",
    "    query: str\n",
    "    decision: Literal[\"code\", \"qgis\", \"concept\"]\n",
    "    documents: Optional[str]\n",
    "    answer: Optional[str]\n",
    "\n",
    "# ----------- PLANNER NODE -----------\n",
    "def planner_node(state: GraphState) -> GraphState:\n",
    "    query = state[\"query\"]\n",
    "    prompt = f\"\"\"\n",
    "You are a reasoning assistant for geospatial tasks.\n",
    "Classify this query into one of:\n",
    "- 'code' for Python or GEE scripting tasks,\n",
    "- 'qgis' for GUI-based QGIS workflows,\n",
    "- 'concept' for general geospatial questions.\n",
    "\n",
    "Query: {query}\n",
    "Respond with only one of: code, qgis, concept.\n",
    "\"\"\"\n",
    "    decision = llm.invoke(prompt).content.strip().lower()\n",
    "    return {**state, \"decision\": decision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- RETRIEVER NODE -----------\n",
    "def retriever_node(state: GraphState) -> GraphState:\n",
    "    docs = retriever.get_relevant_documents(state[\"query\"])\n",
    "    combined = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    return {**state, \"documents\": combined}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- REASONING NODE (Deep Reasoning) -----------\n",
    "def reasoning_node(state: GraphState) -> GraphState:\n",
    "    query = state[\"query\"]\n",
    "    context = state.get(\"documents\", \"\")[:4000]\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are GeoGPT, a scientific geospatial reasoning agent assisting professional users such as ISRO scientists.\n",
    "\n",
    "Use the provided documentation and scientific principles to explain the solution with deep technical clarity.\n",
    "You MUST:\n",
    "1. Identify the user's end goal and break it into scientifically justified sub-tasks.\n",
    "2. For each sub-task, explain the rationale (why this step matters).\n",
    "3. Provide detailed, exact Python (or other GIS tool) code — parameter by parameter — and explain each choice.\n",
    "4. Discuss possible alternatives or optimizations where relevant (e.g., D∞ vs D8, fill sinks vs not, flow threshold calibration).\n",
    "5. Always integrate multiple raster layers logically, describing how each influences the final outcome.\n",
    "6. Clearly mention assumptions (e.g., spatial resolution, CRS, reclassification strategies).\n",
    "7. If data is missing (e.g., no rainfall input), suggest how to acquire or simulate it.\n",
    "\n",
    "Think step-by-step like a scientific assistant guiding a geospatial research workflow.\n",
    "\n",
    "DO NOT summarize. Instead, build a full logical execution plan. Your audience includes senior researchers.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"{system_prompt}\n",
    "\n",
    "--- USER QUERY ---\n",
    "{query}\n",
    "\n",
    "--- RELEVANT DOCS ---\n",
    "{context}\n",
    "\n",
    "Respond now with deep technical reasoning and a complete solution.\n",
    "\"\"\"\n",
    "\n",
    "    answer = llm.invoke(prompt).content.strip()\n",
    "    return {**state, \"answer\": answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- LANGGRAPH FLOW -----------\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"planner\", planner_node)\n",
    "graph.add_node(\"retrieve\", retriever_node)\n",
    "graph.add_node(\"reason\", reasoning_node)\n",
    "graph.add_node(\"output\", lambda state: state)\n",
    "\n",
    "graph.set_entry_point(\"planner\")\n",
    "graph.add_edge(\"planner\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"reason\")\n",
    "graph.add_edge(\"reason\", \"output\")\n",
    "graph.set_finish_point(\"output\")\n",
    "\n",
    "# ----------- COMPILE GRAPH -----------\n",
    "chain = graph.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To conduct a flood risk analysis using Python, the process involves several scientifically-defined stages leveraging geospatial data and hydrological modeling principles. Here’s a detailed plan to achieve the end goal:\n",
      "\n",
      "### End Goal:\n",
      "To perform a flood risk analysis using GIS data by integrating hydrological and topographical modeling.\n",
      "\n",
      "### Sub-tasks:\n",
      "\n",
      "1. **Acquire and Prepare Input Data**\n",
      "   - Obtain Digital Elevation Model (DEM).\n",
      "   - Acquire Rainfall Data.\n",
      "   - Make sure datasets are on the same Coordinate Reference System (CRS) and have matching spatial resolutions.\n",
      "\n",
      "2. **Preprocess DEM data**\n",
      "   - Fill Sinks in DEM to remove artificial depressions.\n",
      "   - Generate flow direction and accumulate flow accumulation.\n",
      "\n",
      "3. **Hydrological Modeling**\n",
      "   - Calculate runoff potential using the Curve Number (CN) approach or similar methods.\n",
      "\n",
      "4. **Combine Hydrologic and Topographic Indices**\n",
      "   - Integrate contributing runoff and topography to delineate flood-prone areas.\n",
      "\n",
      "5. **Output Flood Risk Map**\n",
      "   - Visualize and validate results using additional data sets (e.g., historical flood records).\n",
      "\n",
      "### Detailed Steps with Python Code:\n",
      "\n",
      "#### Step 1: Data Collection and Preparation\n",
      "\n",
      "- **Notes:** Assume input DEM is available. Download necessary precipitation data through sources, e.g., Copernicus Climate Data Store.\n",
      "\n",
      "```python\n",
      "import rasterio\n",
      "from pyproj import CRS\n",
      "\n",
      "# Example code to ensure common CRS and alignment\n",
      "with rasterio.open('DEM.tif') as src:\n",
      "    dem_crs = CRS.from_wkt(src.crs.wkt)\n",
      "    dem_affine = src.transform\n",
      "    dem_data = src.read(1)\n",
      "    \n",
      "# Assuming rainfall data is also a raster\n",
      "with rasterio.open('rainfall.tif') as src:\n",
      "    rain_crs = CRS.from_wkt(src.crs.wkt)\n",
      "\n",
      "assert dem_crs == rain_crs, \"CRS mismatch between DEM and rainfall data.\"\n",
      "\n",
      "# Resample or reprojection logic would be included here as necessary\n",
      "```\n",
      "\n",
      "#### Step 2: Preprocess DEM\n",
      "\n",
      "**Why it matters:** Filling sinks ensures water flows continuously across the surface.\n",
      "\n",
      "```python\n",
      "import whitebox\n",
      "\n",
      "wbt = whitebox.WhiteboxTools()\n",
      "wbt.verbose = True\n",
      "wbt.work_dir = \"/path/to/your/database/\"\n",
      "\n",
      "# Fill sinks\n",
      "wbt.fill_depressions(\n",
      "    dem=\"DEM.tif\", \n",
      "    output=\"filled_dem.tif\"\n",
      ")\n",
      "\n",
      "# Flow direction\n",
      "wbt.d8_pointer(\n",
      "    dem=\"filled_dem.tif\", \n",
      "    output=\"flow_direction.tif\"\n",
      ")\n",
      "\n",
      "# Flow accumulation\n",
      "wbt.d8_flow_accumulation(\n",
      "    i=\"flow_direction.tif\", \n",
      "    output=\"flow_accumulation.tif\",\n",
      "    pntr=True\n",
      ")\n",
      "```\n",
      "\n",
      "#### Step 3: Hydrological Modeling\n",
      "\n",
      "**Why it matters:** Estimating runoff involves calculating potential overland water flow.\n",
      "\n",
      "```python\n",
      "# Simplified runoff estimation using rainfall\n",
      "# Normally involves more sophisticated modeling\n",
      "\n",
      "def calculate_runoff(rainfall, curve_number):\n",
      "    # Example placeholder function for runoff might look like this\n",
      "    return (rainfall - 0.2 * curve_number) * (rainfall > 0.2 * curve_number)\n",
      "\n",
      "runoff = calculate_runoff(rainfall_data, 70)  # Example CN\n",
      "```\n",
      "\n",
      "#### Step 4: Combine Hydrologic and Topographic Indices\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# Logical combination of relevant indices\n",
      "flood_risk = np.where(\n",
      "    (runoff > threshold) & (flow_accum > certain_value), \n",
      "    1, # flood-prone\n",
      "    0  # not flood-prone\n",
      ")\n",
      "```\n",
      "\n",
      "#### Step 5: Output Flood Risk Map\n",
      "\n",
      "```python\n",
      "# Raster output logic assuming flood_risk calculated as per above block\n",
      "with rasterio.open('flood_risk_map.tif', 'w', \n",
      "                   driver='GTiff',\n",
      "                   height=flood_risk.shape[0],\n",
      "                   width=flood_risk.shape[1],\n",
      "                   count=1, \n",
      "                   dtype=flood_risk.dtype) as dst:\n",
      "    dst.write(flood_risk, 1)\n",
      "```\n",
      "\n",
      "### Assumptions\n",
      "- Spatial resolution and CRS of input datasets are accurately matched.\n",
      "- Additional GIS complexity such as reclassification strategies ensure intended analyses.\n",
      "\n",
      "### Alternatives and Optimizations\n",
      "- **D-infinity (D∞) vs. D8:** Use D∞ for more precise flow capturing.\n",
      "- **Rainfall Data Acquisition:** Consider synthetic rainfall modeling if direct measurement is unavailable.\n",
      "\n",
      "This plan incorporates geospatial data integration and hydrological reasoning to derive the flood risk map using Python. The scientific approach ensures reliable outputs by considering both topography and hydrological analysis principles.\n"
     ]
    }
   ],
   "source": [
    "# ----------- SAMPLE RUN -----------\n",
    "response = chain.invoke({\"query\": \"How to do the flood risk anslysis using python only?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
